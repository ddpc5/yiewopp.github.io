WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.130
Now that we have explored the need for

00:00:02.130 --> 00:00:06.285
a data pipeline and the potential problem data pipelines consult,

00:00:06.285 --> 00:00:10.455
we will break down our data pipeline into its important components.

00:00:10.455 --> 00:00:12.615
Let's talk about each one of them.

00:00:12.615 --> 00:00:16.230
First, data pipeline component is data origin.

00:00:16.230 --> 00:00:19.800
Data origin is where data gets into the pipeline.

00:00:19.800 --> 00:00:25.185
Latency constraints of the pipeline are dominated by the type of data origin.

00:00:25.185 --> 00:00:27.660
Velocity is driven by datatype,

00:00:27.660 --> 00:00:29.910
event based or entity based.

00:00:29.910 --> 00:00:34.515
Event data is faster to process compared to entity reference data.

00:00:34.515 --> 00:00:37.470
Event data flows as a data stream.

00:00:37.470 --> 00:00:41.835
We will talk more about entity and event data in later lessons.

00:00:41.835 --> 00:00:46.065
Data might be coming from Data stores,

00:00:46.065 --> 00:00:49.890
Transaction systems, Data Warehouse,

00:00:49.890 --> 00:00:53.745
Data Lake IoT sensors,

00:00:53.745 --> 00:01:00.855
social media, logs, mails, or other documents.

00:01:00.855 --> 00:01:04.634
Next, data processing consists of ingestion,

00:01:04.634 --> 00:01:07.490
that is, getting data from different sources.

00:01:07.490 --> 00:01:10.820
Transformation like cleaning or aggregating,

00:01:10.820 --> 00:01:13.225
and finally, delivering data.

00:01:13.225 --> 00:01:17.675
Sequence of these events could differ depending on the use case.

00:01:17.675 --> 00:01:21.110
Processes could be of many types, MapReduce,

00:01:21.110 --> 00:01:24.730
aggregation, blending, sampling, formatting, etc.

00:01:24.730 --> 00:01:27.800
The right process and the right sequence will define how

00:01:27.800 --> 00:01:31.355
efficiently input data is delivered to the destination.

00:01:31.355 --> 00:01:35.495
Then important data pipeline componet is data storage.

00:01:35.495 --> 00:01:40.190
Data might be stored as an intermediate step for a pipeline.

00:01:40.190 --> 00:01:43.940
Data store could also be data destination.

00:01:43.940 --> 00:01:47.720
There are various choices available for data storage.

00:01:47.720 --> 00:01:52.250
Again, requirements will define if it is Cloud or On-Prem,

00:01:52.250 --> 00:01:54.670
what type of DB is used,

00:01:54.670 --> 00:01:57.900
or Data Warehouse, or a Data Lake is used.

00:01:57.900 --> 00:02:00.435
Finally, data's destination.

00:02:00.435 --> 00:02:04.115
Timeliness is a data destination driven requirement.

00:02:04.115 --> 00:02:08.855
How quickly is data needed for the destination is timeliness?

00:02:08.855 --> 00:02:14.320
Sometimes a subset of data might be needed in real time and not the whole set.

00:02:14.320 --> 00:02:16.230
You recognize what is needed,

00:02:16.230 --> 00:02:18.960
Vin, and move data accordingly.

00:02:18.960 --> 00:02:22.470
Data destination could be Datastore,

00:02:22.470 --> 00:02:26.730
like Data Warehouse, Data Mart, or Data Lake.

00:02:26.730 --> 00:02:31.099
It could be an application such as Dashboard,

00:02:31.099 --> 00:02:34.830
ML Apps, or Analytics Apps.

