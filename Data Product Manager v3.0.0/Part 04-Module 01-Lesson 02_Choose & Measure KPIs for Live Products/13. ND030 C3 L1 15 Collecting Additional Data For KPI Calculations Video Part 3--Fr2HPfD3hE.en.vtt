WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.430
Here's an example of a business scenario when

00:00:02.430 --> 00:00:07.250
a Product Manager would need to ensure that instrumentation is added to a feature.

00:00:07.250 --> 00:00:13.215
In this scenario, a company is launching a walkthrough to help onboard new users.

00:00:13.215 --> 00:00:16.410
The walkthrough is a basic popover that contains

00:00:16.410 --> 00:00:20.150
three slides with information on how the app functions.

00:00:20.150 --> 00:00:22.710
If they want to navigate through the slides,

00:00:22.710 --> 00:00:25.215
a user can click on next button,

00:00:25.215 --> 00:00:28.465
and there's a button to return to previous slides.

00:00:28.465 --> 00:00:32.660
At any point, a user can click an X to close out the module.

00:00:32.660 --> 00:00:36.290
Finally, the user sees a complete button on the last slide,

00:00:36.290 --> 00:00:39.005
which they can use to close the pop-up module.

00:00:39.005 --> 00:00:40.920
Here is the question for you.

00:00:40.920 --> 00:00:44.810
What information would be important for a product manager to capture

00:00:44.810 --> 00:00:49.000
in order to know whether this new onboarding module is successful?

00:00:49.000 --> 00:00:51.875
To know whether the walk through module is successful,

00:00:51.875 --> 00:00:54.995
a product manager needs to ensure data is collected,

00:00:54.995 --> 00:00:59.740
such as acquisition metrics on which users saw that onboarding module.

00:00:59.740 --> 00:01:03.770
This means knowing which user IDs were exposed to the walk through module.

00:01:03.770 --> 00:01:06.200
It also means tracking information that might

00:01:06.200 --> 00:01:08.480
change about a user from session to session,

00:01:08.480 --> 00:01:11.540
such as their device type and operating system.

00:01:11.540 --> 00:01:16.340
Next, we need to know if a customer truly use the walk through feature.

00:01:16.340 --> 00:01:18.815
Since every new user sees the walk through,

00:01:18.815 --> 00:01:20.645
but can leave at any time.

00:01:20.645 --> 00:01:25.615
This will mean instrumenting to understand how a given user interacted with the module.

00:01:25.615 --> 00:01:28.460
For example, recording events so that you can

00:01:28.460 --> 00:01:31.925
calculate the time a user spent on each of the three slides.

00:01:31.925 --> 00:01:36.220
This can be accomplished by tracking the time each next slide button is clicked.

00:01:36.220 --> 00:01:37.790
Note here that you should avoid

00:01:37.790 --> 00:01:41.425
the anti-pattern of doing something automatically for a user.

00:01:41.425 --> 00:01:43.970
If the slides transitioned without the user taking

00:01:43.970 --> 00:01:46.760
action and you only track the page view time,

00:01:46.760 --> 00:01:48.710
there would be no way to distinguish,

00:01:48.710 --> 00:01:52.760
if a user had taken an action and actively interacted with the feature.

00:01:52.760 --> 00:01:54.710
It is always important to know,

00:01:54.710 --> 00:01:58.295
whether and when the user consciously chose to do something.

00:01:58.295 --> 00:02:01.355
To know which customers made use of the onboarding module,

00:02:01.355 --> 00:02:05.815
understanding the average length of time is spent in the entire module will be important.

00:02:05.815 --> 00:02:08.720
By tracking when a customer closes the module,

00:02:08.720 --> 00:02:11.225
either via the x or complete button,

00:02:11.225 --> 00:02:14.045
you will later be able to see whether a given customer

00:02:14.045 --> 00:02:17.720
actually spent time reading and interacting with the Onboarding.

00:02:17.720 --> 00:02:22.085
Collecting this data on user acquisition and activation of the feature,

00:02:22.085 --> 00:02:26.585
enables Product managers to know how a customer use the walk through feature.

00:02:26.585 --> 00:02:31.445
Success won't just be measured by the percent of new users who interact with the module.

00:02:31.445 --> 00:02:35.335
However, but by considering retention and revenue metrics.

00:02:35.335 --> 00:02:37.795
In the case of an onboarding module,

00:02:37.795 --> 00:02:41.305
product managers wouldn't need to add any new instrumentation,

00:02:41.305 --> 00:02:44.485
to see if the user's interest in the feature is retained.

00:02:44.485 --> 00:02:47.275
The module is only seen one time by users,

00:02:47.275 --> 00:02:50.725
so retention isn't relevant for this particular feature.

00:02:50.725 --> 00:02:53.080
The product managers wouldn't need to add

00:02:53.080 --> 00:02:55.975
any new instrumentation in the revenue side either,

00:02:55.975 --> 00:03:00.575
since the Onboarding walk through feature does not generate any revenue directly.

00:03:00.575 --> 00:03:05.185
While the feature doesn't need additional retention and revenue instrumentation,

00:03:05.185 --> 00:03:08.760
calculating retention and revenue of customers at the product level,

00:03:08.760 --> 00:03:12.500
is highly relevant when considering if the feature was a success.

00:03:12.500 --> 00:03:16.390
By adding instrumentation that allows us to know if a customer

00:03:16.390 --> 00:03:20.960
truly read the walk through versus speeding through or closing out the walk through,

00:03:20.960 --> 00:03:24.535
we know whether any given customer made use of the feature

00:03:24.535 --> 00:03:28.805
and that gives us the power to compare feature usage to our KPIs.

00:03:28.805 --> 00:03:31.700
For example, is user satisfaction

00:03:31.700 --> 00:03:35.180
different in the first week for onboarding module users?

00:03:35.180 --> 00:03:37.910
Is the user features highlighted in the walk through

00:03:37.910 --> 00:03:42.160
higher with walk through module users than users who skipped the module?

00:03:42.160 --> 00:03:46.555
Are users who actually read the onboarding module, retained longer?

00:03:46.555 --> 00:03:49.415
By instrumenting the Onboarding module well,

00:03:49.415 --> 00:03:55.170
all of these important KPIs can be calculated and the success of the feature measured.

